# Taha Mansouri

**Lecturer in AI | Responsible/Trustworthy AI Â· Computer Vision Â· LLMs & Multimodal AI | University of Salford**

[![University of Salford](https://img.shields.io/badge/University%20of%20Salford-Lecturer%20in%20AI-7A003C?logo=academia&logoColor=white)](https://www.salford.ac.uk/our-staff/taha-mansouri)
[![ORCID](https://img.shields.io/badge/ORCID-0000--0003--1539--5546-A6CE39?logo=orcid&logoColor=white)](https://orcid.org/0000-0003-1539-5546)
[![Google Scholar](https://img.shields.io/badge/Google%20Scholar-Profile-4285F4?logo=googlescholar&logoColor=white)](https://scholar.google.com/)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Taha%20Mansouri-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/taha-mansouri-7969095a/)
[![GitHub followers](https://img.shields.io/github/followers/tahamsi?style=social)](https://github.com/tahamsi)

---

## About Me

I am a **Lecturer in Artificial Intelligence** at the **University of Salford**, working at the intersection of **Responsible/Trustworthy AI**, **Computer Vision**, and **LLMs / multimodal AI**.

My work combines **academic research** with **industry-facing applied AI**, with an emphasis on systems that are **fair**, **explainable**, **robust**, and **deployable in real-world settings**.

I hold dual PhDs in **Artificial Intelligence** and **Information Technology Management**, and I work across research, teaching, supervision, and collaborative innovation projects.

---

## Current Focus

- **Responsible / Trustworthy AI**  
  Fairness, explainability, transparency, robustness, governance, auditing
- **Computer Vision & Multimodal AI**  
  Visual understanding, perception pipelines, applied vision systems
- **LLMs and Agentic AI**  
  Verifiable reasoning, retrieval-augmented systems, orchestration
- **AI for Education**  
  Assessment, learning support, curriculum design, monitoring tools
- **Applied AI Translation**  
  Industry collaboration, evaluation, prototyping, deployment-aware design

---

## Selected Repositories (Organised by Theme)

### Responsible / Trustworthy AI
- [`trustworthy-ai-playbook`](https://github.com/tahamsi/trustworthy-ai-playbook)  
  Practical playbook for ethical AI in SMEs (fairness, mitigation, explainability, model documentation).
- [`instance-wise-explanation`](https://github.com/tahamsi/instance-wise-explanation)  
  Work on explainability / instance-level interpretation.
- [`fairfactor-temporal-fer`](https://github.com/tahamsi/fairfactor-temporal-fer)  
  Fairness-aware temporal facial expression recognition.

### LLMs, RAG, and Agentic Systems
- [`aegisrag-poe`](https://github.com/tahamsi/aegisrag-poe)  
  Proof-carrying retrieval system for long-context, verifiable LLM reasoning.
- [`stateful_rag_orchestrator`](https://github.com/tahamsi/stateful_rag_orchestrator)  
  Stateful orchestration patterns for retrieval-augmented systems.
- [`agent-forge`](https://github.com/tahamsi/agent-forge)  
  Policy-gated agent platform for controlled agent workflows.
- [`llm-fine-tuning`](https://github.com/tahamsi/llm-fine-tuning)  
  Practical LLM/VLM fine-tuning experiments and workflows.

### Computer Vision & Multimodal AI
- [`computer-vision`](https://github.com/tahamsi/computer-vision)  
  Hands-on examples spanning classification, detection, segmentation, tracking, and generative methods.
- [`cnn-transformers-cv-labs`](https://github.com/tahamsi/cnn-transformers-cv-labs)  
  Masterâ€™s-level teaching labs for CNNs and Vision Transformers.
- [`facial_expression_detection`](https://github.com/tahamsi/facial_expression_detection)  
  Video-based facial expression analysis and detector sanity-checking workflows.
- [`qwen-vl-caption-api`](https://github.com/tahamsi/qwen-vl-caption-api)  
  Vision-language captioning API experiments.
- [`vlm`](https://github.com/tahamsi/vlm), [`univlm`](https://github.com/tahamsi/univlm), [`blip-2`](https://github.com/tahamsi/blip-2), [`florence-2`](https://github.com/tahamsi/florence-2)  
  Multimodal / VLM experimentation repos.

### Privacy, Safety, and Robust Systems
- [`cappa`](https://github.com/tahamsi/cappa)  
  Prompt-driven inpainting system for privacy-preserving image/video processing.

---

## Teaching & Learning Resources

I share selected teaching and lab materials to support practical learning in AI and computer vision.

- **Computer Vision examples and notebooks:** [`computer-vision`](https://github.com/tahamsi/computer-vision)
- **CNNs & Vision Transformers labs (MSc-level):** [`cnn-transformers-cv-labs`](https://github.com/tahamsi/cnn-transformers-cv-labs)

I aim to keep teaching resources reproducible, practical, and aligned with real-world AI engineering constraints.

---

## Selected Publications (Short List)

A small set of publications/outputs that align with the repositories and current research themes:

- **Inclusive prompt engineering for large language models:** a modular framework for ethical, structured, and adaptive AI
- **AIMA:** an agentic AI approach to vulnerability scanning of higher-education assessment
- **A novel triplet loss architecture with visual explanation** for detecting unwanted bolt rotation in safety-critical environments

**Full publication list:**  
- [University profile](https://www.salford.ac.uk/our-staff/taha-mansouri)  
- [Google Scholar](https://scholar.google.com/)  
- [ORCID](https://orcid.org/0000-0003-1539-5546)

> I keep the list short here so GitHub stays focused on code and reproducible artefacts rather than turning into a second CV.

---

## Collaboration

I welcome collaboration in:

- Responsible / Trustworthy AI
- Explainable AI and AI governance
- Computer Vision and multimodal AI
- LLMs / RAG / agentic AI (especially verifiable and auditable systems)
- AI for Education

I am also open to **PhD enquiries and research collaboration** in these areas.

ðŸ“© **Contact / profiles**
- [University profile](https://www.salford.ac.uk/our-staff/taha-mansouri)
- [LinkedIn](https://www.linkedin.com/in/taha-mansouri-7969095a/)
- Email: `t.mansouri@salford.ac.uk`

---

## GitHub Visual Overview

<!-- Useful visuals only. No spinning neon nonsense. -->

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=tahamsi&show_icons=true&hide_title=true&include_all_commits=true&count_private=false" alt="GitHub stats" />
</p>

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=tahamsi&layout=compact&langs_count=8" alt="Top languages" />
</p>

<p align="center">
  <img src="https://github-readme-activity-graph.vercel.app/graph?username=tahamsi&hide_border=true" alt="GitHub activity graph" />
</p>

---

## Research-to-Repository Map

```mermaid
mindmap
  root((Taha Mansouri))
    Responsible / Trustworthy AI
      Fairness
      Explainability
      Governance
      Auditing
      trustworthy-ai-playbook
      instance-wise-explanation
      fairfactor-temporal-fer
    LLMs / Agentic AI
      Verifiable reasoning
      RAG orchestration
      aegisrag-poe
      stateful_rag_orchestrator
      agent-forge
      llm-fine-tuning
    Computer Vision / Multimodal AI
      Detection
      Segmentation
      FER
      VLMs
      computer-vision
      cnn-transformers-cv-labs
      facial_expression_detection
      qwen-vl-caption-api
    AI for Education
      Assessment
      Learning support
      AIMA
